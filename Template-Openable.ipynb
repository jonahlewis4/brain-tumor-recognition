{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "12D9vASsof-o46iuZT6Y9qkAt-_7XKbaT",
      "authorship_tag": "ABX9TyOaR8HkO+oIyk6FX4SB8637",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jonahlewis4/brain-tumor-recognition/blob/main/Template-Openable.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "X9NDSzR4EcRp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "388559aa-1cb5-4447-ceef-27536d7e0a78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "current direcotry files ['MyDrive', '.shortcut-targets-by-id', '.file-revisions-by-id', '.Trash-0', '.Encrypted']\n",
            "this is past opening the tumor directory\n",
            "this is past opening the non-tumor directory\n",
            "Number of training samples: 202\n",
            "Number of testing samples: 51\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 4s/step - accuracy: 0.5423 - loss: 0.8349 - val_accuracy: 0.7619 - val_loss: 0.4971\n",
            "Epoch 2/5\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 4s/step - accuracy: 0.7795 - loss: 0.5015 - val_accuracy: 0.7619 - val_loss: 0.4523\n",
            "Epoch 3/5\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 4s/step - accuracy: 0.8242 - loss: 0.5262 - val_accuracy: 0.7619 - val_loss: 0.4332\n",
            "Epoch 4/5\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 4s/step - accuracy: 0.8754 - loss: 0.3624 - val_accuracy: 0.7619 - val_loss: 0.4696\n",
            "Epoch 5/5\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 4s/step - accuracy: 0.8628 - loss: 0.3441 - val_accuracy: 0.7619 - val_loss: 0.4448\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 682ms/step - accuracy: 0.7676 - loss: 0.5058\n",
            "Test accuracy: 0.7450980544090271\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "# Set up the directories where your images are stored.\n",
        "# Make sure to update these paths to where your actual image folders are located.\n",
        "tumor_dir = 'drive/MyDrive/brain-tumors/archive/yes'       # Directory with brains having tumors\n",
        "non_tumor_dir = 'drive/MyDrive/brain-tumors/archive/no' # Directory with brains without tumors\n",
        "\n",
        "\n",
        "# Define the target size for the images (width, height). Feel free to adjust as needed.\n",
        "target_size = (256, 256)\n",
        "\n",
        "# Lists to hold the image data and corresponding labels.\n",
        "data = []\n",
        "labels = []\n",
        "\n",
        "current_directory = os.getcwd()\n",
        "print(current_directory)\n",
        "print('current direcotry files', os.listdir('./drive'))\n",
        "\n",
        "def process_images(directory, label):\n",
        "    \"\"\"\n",
        "    Loads images from the specified directory, converts them to greyscale,\n",
        "    resizes them to the target size, and appends them to the global lists.\n",
        "    \"\"\"\n",
        "    for filename in os.listdir(directory):\n",
        "        # Check for common image file extensions.\n",
        "        if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "            img_path = os.path.join(directory, filename)\n",
        "            try:\n",
        "                # Open the image, convert it to greyscale, and resize it.\n",
        "                img = Image.open(img_path).convert('L')\n",
        "                img = img.resize(target_size)\n",
        "                # Convert the image to a NumPy array.\n",
        "                img_array = np.array(img)\n",
        "                data.append(img_array)\n",
        "                labels.append(label)\n",
        "            except Exception as e:\n",
        "                print(f\"Could not process {img_path}: {e}\")\n",
        "\n",
        "# Process images from both directories.\n",
        "process_images(tumor_dir, label=1)      # Label 1 indicates a tumor.\n",
        "print(\"this is past opening the tumor directory\")\n",
        "process_images(non_tumor_dir, label=0)  # Label 0 indicates no tumor.\n",
        "print(\"this is past opening the non-tumor directory\")\n",
        "\n",
        "\n",
        "# Create a Pandas DataFrame with the image data and labels.\n",
        "df = pd.DataFrame({\n",
        "    'image': data,\n",
        "    'label': labels\n",
        "})\n",
        "\n",
        "# Split the DataFrame into training (80%) and testing (20%) sets.\n",
        "train_df, test_df = train_test_split(df, test_size=0.2, stratify=df['label'], random_state=65)\n",
        "\n",
        "print(f\"Number of training samples: {len(train_df)}\")\n",
        "print(f\"Number of testing samples: {len(test_df)}\")\n",
        "\n",
        "# Preprocess the training and testing data\n",
        "# Stack the images and reshape to include channel dimension, then normalize.\n",
        "def prepare_data(df, target_size):\n",
        "    images = np.stack(df['image'].values)\n",
        "    images = images.reshape(-1, target_size[0], target_size[1], 1) / 255.0\n",
        "    labels = np.array(df['label'].values)\n",
        "    return images, labels\n",
        "\n",
        "train_images, train_labels = prepare_data(train_df, target_size)\n",
        "test_images, test_labels = prepare_data(test_df, target_size)\n",
        "\n",
        "# Using keras we compile a CNN.\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(target_size[0], target_size[1], 1)),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model.\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model.\n",
        "history = model.fit(train_images, train_labels, epochs=5, batch_size=30, validation_split=0.1)\n",
        "\n",
        "# Evaluate the model on the test set.\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print(\"Test accuracy:\", test_acc)"
      ]
    }
  ]
}